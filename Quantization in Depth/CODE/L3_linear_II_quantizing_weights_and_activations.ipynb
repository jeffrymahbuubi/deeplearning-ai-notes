{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9ln8ylCKHsx"
   },
   "source": [
    "# L3-E - Linear Quantization II: Quantizing Weights & Activations for Inference\n",
    "\n",
    "In this lesson, you will continue to learn different ways of performing linear quantization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to import all of the functions you have used before in the previous lesson(s) of `Linear Quantization II` to follow along with the video.\n",
    "\n",
    "- To access the `helper.py` file, you can click `File --> Open...`, on the top left."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 64,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:16:03.771231Z",
     "start_time": "2025-03-04T07:15:57.412963Z"
    }
   },
   "source": [
    "import torch\n",
    "\n",
    "from helper import linear_q_symmetric, get_q_scale_symmetric"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qUw1gQUu5yIe"
   },
   "source": [
    "## Linear Quantization: Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `W8A32` means weights in 8-bits and activations in 32-bits.\n",
    "- For simplicity, the linear layer will be without bias."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 149,
    "id": "vGll7vBT6BGI",
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:04.899674Z",
     "start_time": "2025-03-04T07:18:04.892679Z"
    }
   },
   "source": [
    "def quantized_linear_W8A32_without_bias(input, q_w, s_w, z_w):\n",
    "    assert input.dtype == torch.float32\n",
    "    assert q_w.dtype == torch.int8\n",
    "\n",
    "    dequantized_weight = q_w.to(torch.float32) * s_w + z_w\n",
    "    output = torch.nn.functional.linear(input, dequantized_weight)\n",
    "    \n",
    "    return output"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1705361606028,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 30,
    "id": "7sPRcXM-AHTR",
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:05.753517Z",
     "start_time": "2025-03-04T07:18:05.734436Z"
    }
   },
   "source": [
    "input = torch.tensor([1, 2, 3], dtype=torch.float32)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1705361607599,
     "user": {
      "displayName": "Marc Sun",
      "userId": "00829270524676809963"
     },
     "user_tz": 300
    },
    "height": 64,
    "id": "o9IQsM1295iz",
    "outputId": "38f08506-db80-40ec-9840-e184a8a6fe5a",
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:07.218259Z",
     "start_time": "2025-03-04T07:18:07.196609Z"
    }
   },
   "source": [
    "weight = torch.tensor([[-2,   -1.13, 0.42],\n",
    "                       [-1.51, 0.25, 1.62],\n",
    "                       [0.23,  1.35, 2.15]])"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:22.899619Z",
     "start_time": "2025-03-04T07:18:22.887085Z"
    }
   },
   "source": [
    "q_w, s_w  = linear_q_symmetric(weight)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:23.753775Z",
     "start_time": "2025-03-04T07:18:23.732723Z"
    }
   },
   "source": [
    "q_w"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-118,  -67,   25],\n",
       "        [ -89,   15,   96],\n",
       "        [  14,   80,  127]], dtype=torch.int8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:26.415757Z",
     "start_time": "2025-03-04T07:18:26.390755Z"
    }
   },
   "source": [
    "s_w"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016929134609192376"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 81,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:40.694937Z",
     "start_time": "2025-03-04T07:18:40.588895Z"
    }
   },
   "source": [
    "output = quantized_linear_W8A32_without_bias(input,\n",
    "                                             q_w,\n",
    "                                             s_w,\n",
    "                                             0)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:41.301496Z",
     "start_time": "2025-03-04T07:18:41.278234Z"
    }
   },
   "source": [
    "print(f\"This is the W8A32 output: {output}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the W8A32 output: tensor([-2.9965,  3.8768,  9.3957])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:43.460739Z",
     "start_time": "2025-03-04T07:18:43.453734Z"
    }
   },
   "source": [
    "fp32_output = torch.nn.functional.linear(input, weight)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "height": 30,
    "ExecuteTime": {
     "end_time": "2025-03-04T07:18:43.991457Z",
     "start_time": "2025-03-04T07:18:43.981904Z"
    }
   },
   "source": [
    "print(f\"This is the output if we don't quantize: {fp32_output}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the output if we don't quantize: tensor([-3.0000,  3.8500,  9.3800])\n"
     ]
    }
   ],
   "execution_count": 12
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NgmjMISuIyzF",
    "3dMVgqcNJCqE",
    "MFx2m7RmzRd5",
    "l6XbkmOzYMrC",
    "8NS1TnQt6E6v"
   ],
   "provenance": [
    {
     "file_id": "12_pQW6LB80u98m72_YKwM4ph7eb5Uf3g",
     "timestamp": 1705360205453
    },
    {
     "file_id": "1U9pm4j_uAD8EO7OrEPvdpwFjQKO3suuH",
     "timestamp": 1700237940920
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
